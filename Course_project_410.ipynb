{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Course_project_410.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtwexhukQ5Cn",
        "scrolled": true,
        "outputId": "9995791b-baa2-473a-9cad-621179a4b589"
      },
      "source": [
        "!pip install jsonlines"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from jsonlines) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAhreXcYUBTm",
        "outputId": "c8b9775b-a1ef-4fe7-cacb-6981e85d0018"
      },
      "source": [
        "#create readable train data csv\n",
        "\n",
        "import os\n",
        "import jsonlines\n",
        "import csv\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "data = []\n",
        "\n",
        "with open(\"train.jsonl\",\"r+\",encoding='utf-8') as f:\n",
        "    for item in jsonlines.Reader(f):\n",
        "        if item['label'] == 'SARCASM':\n",
        "            item['label'] = 0\n",
        "        else:\n",
        "            item['label'] = 1\n",
        "\n",
        "        data.append(item)\n",
        "\n",
        "with open('twitter.csv', 'w+', newline='', encoding='utf-8') as f:\n",
        "    csv_writer = csv.writer(f)\n",
        "    csv_head = ['context', 'response', 'label']\n",
        "    csv_writer.writerow(csv_head)\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        data_row = [(''.join(data[i]['context'])).replace('@USER', '').replace('<URL>',''),\n",
        "                    (data[i]['response']).replace('@USER', '').replace('<URL>',''), data[i]['label']]\n",
        "        csv_writer.writerow(data_row)\n",
        "\n",
        "total = pd.read_csv(\"twitter.csv\")\n",
        "\n",
        "index = set(range(total.shape[0]))\n",
        "K_fold = []\n",
        "for i in range(5):\n",
        "    if i == 4:\n",
        "        tmp = index\n",
        "    else:\n",
        "        tmp = random.sample(index, int(1.0 / 5 * total.shape[0]))\n",
        "    index = index - set(tmp)\n",
        "    print(\"Number:\", len(tmp))\n",
        "    K_fold.append(tmp)\n",
        "\n",
        "for i in range(5):\n",
        "    print(\"Fold\", i)\n",
        "    os.system(\"mkdir data_{}\".format(i))\n",
        "    dev_index = list(K_fold[i])\n",
        "    train_index = []\n",
        "    for j in range(5):\n",
        "        if j != i:\n",
        "            train_index += K_fold[j]\n",
        "    total.iloc[train_index].to_csv(\"data_{}/train.csv\".format(i))\n",
        "    total.iloc[dev_index].to_csv(\"data_{}/dev.csv\".format(i))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number: 1000\n",
            "Number: 1000\n",
            "Number: 1000\n",
            "Number: 1000\n",
            "Number: 1000\n",
            "Fold 0\n",
            "Fold 1\n",
            "Fold 2\n",
            "Fold 3\n",
            "Fold 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jag_Pj7tQklb",
        "outputId": "b8a19b8f-d75e-402a-f90f-2661c70b4a9c"
      },
      "source": [
        "#create readable test data csv\n",
        "\n",
        "data = []\n",
        "\n",
        "with open('test.jsonl',\"r+\",encoding='utf-8') as f:\n",
        "    for item in jsonlines.Reader(f):\n",
        "        data.append(item)\n",
        "\n",
        "with open('testdata.csv', 'w+', newline='', encoding='utf-8') as f:\n",
        "    csv_writer = csv.writer(f)\n",
        "    csv_head = ['context', 'response', 'id']\n",
        "    csv_writer.writerow(csv_head)\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        data_row = [(''.join(data[i]['context'])).replace('@USER', '').replace('<URL>', ''),\n",
        "                    (data[i]['response']).replace('@USER', '').replace('<URL>', ''), data[i]['id']]\n",
        "        csv_writer.writerow(data_row)\n",
        "\n",
        "total = pd.read_csv(\"testdata.csv\")\n",
        "\n",
        "index = set(range(total.shape[0]))\n",
        "K_fold = []\n",
        "for i in range(5):\n",
        "    if i == 4:\n",
        "        tmp = index\n",
        "    else:\n",
        "        tmp = random.sample(index, int(1.0 / 5 * total.shape[0]))\n",
        "    index = index - set(tmp)\n",
        "    print(\"Number:\", len(tmp))\n",
        "    K_fold.append(tmp)\n",
        "\n",
        "for i in range(5):\n",
        "    print(\"Fold\", i)\n",
        "    os.system(\"mkdir data_{}\".format(i))\n",
        "    dev_index = list(K_fold[i])\n",
        "    train_index = []\n",
        "    for j in range(5):\n",
        "        if j != i:\n",
        "            train_index += K_fold[j]\n",
        "    total.iloc[train_index].to_csv(\"data_{}/train.csv\".format(i))\n",
        "    total.iloc[dev_index].to_csv(\"data_{}/dev.csv\".format(i))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number: 360\n",
            "Number: 360\n",
            "Number: 360\n",
            "Number: 360\n",
            "Number: 360\n",
            "Fold 0\n",
            "Fold 1\n",
            "Fold 2\n",
            "Fold 3\n",
            "Fold 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Exl-xU_gaPx7",
        "outputId": "318220bb-90df-42ae-ce27-05d38c755c30"
      },
      "source": [
        "!pip install sentencepiece\n",
        "!brew install zeromq\n",
        "!brew install pkgconfig\n",
        "!pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.91)\n",
            "/bin/bash: brew: command not found\n",
            "/bin/bash: brew: command not found\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwruXiTXsORZ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast, RobertaTokenizer, RobertaTokenizerFast\n",
        "\n",
        "# specify CPU/GPU\n",
        "device = torch.device(\"cpu\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "87T5BetZQYQv",
        "outputId": "539ecd8a-a67c-4947-c35a-eac168953a19"
      },
      "source": [
        "td = pd.read_csv(\"testdata.csv\")\n",
        "td['text'] = td['response']+td['context']  \n",
        "\n",
        "df = pd.read_csv(\"twitter.csv\")\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>response</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A minor child deserves privacy and should be k...</td>\n",
              "      <td>I don't get this .. obviously you do care o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why is he a loser ? He's just a Press Secret...</td>\n",
              "      <td>trying to protest about . Talking about him ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Donald J . Trump is guilty as charged . The ev...</td>\n",
              "      <td>He makes an insane about of money from the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jamie Raskin tanked Doug Collins . Collins loo...</td>\n",
              "      <td>Meanwhile Trump won't even release his SAT s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Man ... y ’ all gone “ both sides ” the apocal...</td>\n",
              "      <td>Pretty Sure the Anti-Lincoln Crowd Claimed T...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             context  ... label\n",
              "0  A minor child deserves privacy and should be k...  ...     0\n",
              "1    Why is he a loser ? He's just a Press Secret...  ...     0\n",
              "2  Donald J . Trump is guilty as charged . The ev...  ...     0\n",
              "3  Jamie Raskin tanked Doug Collins . Collins loo...  ...     0\n",
              "4  Man ... y ’ all gone “ both sides ” the apocal...  ...     0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOckP_sYQcda",
        "outputId": "d7c9b99b-6b1f-480c-9514-e2b636dc483d"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_F9FfyFSQl_5",
        "outputId": "4159c118-f832-4ba0-985f-bbb817d1336f"
      },
      "source": [
        "# check class distribution\n",
        "df['label'].value_counts(normalize = True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.5\n",
              "0    0.5\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "hPVu_ZPTU3Q0",
        "outputId": "6292b7ad-ca61-432f-cac2-489cccf457b6"
      },
      "source": [
        "td.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>response</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Well now that ’ s problematic AF   My 5 year o...</td>\n",
              "      <td>My 3 year old , that just finished reading ...</td>\n",
              "      <td>twitter_1</td>\n",
              "      <td>My 3 year old , that just finished reading ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Last week the Fake News said that a section of...</td>\n",
              "      <td>How many verifiable lies has he told now ? 1...</td>\n",
              "      <td>twitter_2</td>\n",
              "      <td>How many verifiable lies has he told now ? 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Let ’ s Aplaud Brett When he deserves it he c...</td>\n",
              "      <td>Maybe Docs just a scrub of a coach ... I me...</td>\n",
              "      <td>twitter_3</td>\n",
              "      <td>Maybe Docs just a scrub of a coach ... I me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Women generally hate this president . What's u...</td>\n",
              "      <td>is just a cover up for the real hate inside ...</td>\n",
              "      <td>twitter_4</td>\n",
              "      <td>is just a cover up for the real hate inside ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dear media Remoaners , you excitedly sharing c...</td>\n",
              "      <td>The irony being that he even has to ask why .</td>\n",
              "      <td>twitter_5</td>\n",
              "      <td>The irony being that he even has to ask why...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             context  ...                                               text\n",
              "0  Well now that ’ s problematic AF   My 5 year o...  ...     My 3 year old , that just finished reading ...\n",
              "1  Last week the Fake News said that a section of...  ...    How many verifiable lies has he told now ? 1...\n",
              "2   Let ’ s Aplaud Brett When he deserves it he c...  ...     Maybe Docs just a scrub of a coach ... I me...\n",
              "3  Women generally hate this president . What's u...  ...    is just a cover up for the real hate inside ...\n",
              "4  Dear media Remoaners , you excitedly sharing c...  ...     The irony being that he even has to ask why...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "xalsFDNyQp66",
        "outputId": "cc55472d-4285-45da-e43c-dedaab0acac2"
      },
      "source": [
        "#May try three kinds of situations: context alone, reponse alone and context +response to see which one performs the best, here I just combine the response and context\n",
        "df['text'] = df['context']+df['response']\n",
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>response</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A minor child deserves privacy and should be k...</td>\n",
              "      <td>I don't get this .. obviously you do care o...</td>\n",
              "      <td>0</td>\n",
              "      <td>A minor child deserves privacy and should be k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why is he a loser ? He's just a Press Secret...</td>\n",
              "      <td>trying to protest about . Talking about him ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Why is he a loser ? He's just a Press Secret...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Donald J . Trump is guilty as charged . The ev...</td>\n",
              "      <td>He makes an insane about of money from the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Donald J . Trump is guilty as charged . The ev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jamie Raskin tanked Doug Collins . Collins loo...</td>\n",
              "      <td>Meanwhile Trump won't even release his SAT s...</td>\n",
              "      <td>0</td>\n",
              "      <td>Jamie Raskin tanked Doug Collins . Collins loo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Man ... y ’ all gone “ both sides ” the apocal...</td>\n",
              "      <td>Pretty Sure the Anti-Lincoln Crowd Claimed T...</td>\n",
              "      <td>0</td>\n",
              "      <td>Man ... y ’ all gone “ both sides ” the apocal...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             context  ...                                               text\n",
              "0  A minor child deserves privacy and should be k...  ...  A minor child deserves privacy and should be k...\n",
              "1    Why is he a loser ? He's just a Press Secret...  ...    Why is he a loser ? He's just a Press Secret...\n",
              "2  Donald J . Trump is guilty as charged . The ev...  ...  Donald J . Trump is guilty as charged . The ev...\n",
              "3  Jamie Raskin tanked Doug Collins . Collins loo...  ...  Jamie Raskin tanked Doug Collins . Collins loo...\n",
              "4  Man ... y ’ all gone “ both sides ” the apocal...  ...  Man ... y ’ all gone “ both sides ” the apocal...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XryjXIYhQ_gM"
      },
      "source": [
        "train_text, val_text, train_labels, val_labels = train_test_split(df['text'], df['label'], \n",
        "                                                                    random_state=2018, \n",
        "                                                                    test_size=0.3, \n",
        "                                                                    stratify=df['label'])\n",
        "\n",
        "test_text = td['text']    "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG9h0KEotC_r"
      },
      "source": [
        "# import RoBERT-base pretrained model\n",
        "# roberta = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "roberta = AutoModel.from_pretrained('roberta-base')\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPnTpMt8tJLp"
      },
      "source": [
        "# sample data\n",
        "text = [\"this is a Roberta model tutorial\", \"we will fine-tune a Roberta model\"]\n",
        "\n",
        "# encode text\n",
        "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmGxHveVtJ4f",
        "outputId": "a49b0de1-17e9-4773-88d5-3457eea99d9a"
      },
      "source": [
        "print(sent_id)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': [[0, 9226, 16, 10, 1738, 102, 1421, 35950, 2, 1, 1, 1], [0, 1694, 40, 2051, 12, 90, 4438, 10, 1738, 102, 1421, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "TGYSbQzUtLwS",
        "outputId": "53616502-1a25-4656-ed66-f6e022862e82"
      },
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6883808860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMzKcnYxtOFP"
      },
      "source": [
        "#could change to get best answer, maybe 400 better? could try \n",
        "max_seq_len = 200"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6mRLN3vtQXX",
        "outputId": "e790a480-6b9d-4228-b30b-9fd0b27cdad5"
      },
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD_IfCzotVxj"
      },
      "source": [
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "# for validation set\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "#test_y = torch.tensor(test_labels.tolist())"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaDhHt7NtZRZ"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size  30 seems better than 32? may try other paras\n",
        "batch_size = 30\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc380qoYtfE5"
      },
      "source": [
        "# freeze all the parameters\n",
        "for param in roberta.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0nqk53itiDN"
      },
      "source": [
        "class RoBERTa_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, roberta):\n",
        "      \n",
        "      super(RoBERTa_Arch, self).__init__()\n",
        "\n",
        "      self.roberta = roberta \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.roberta(sent_id, attention_mask=mask)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyVFwzk5tjXo"
      },
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = RoBERTa_Arch(roberta)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGHNgzsDtqfP"
      },
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MHWVvVDttbi",
        "outputId": "2d324375-8947-4c2b-c5dc-37983618516f"
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
        "\n",
        "print(class_wts)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytxaBXCDtwk_"
      },
      "source": [
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 10"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlrAx2VLt0F5"
      },
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmW_LsLct4lQ"
      },
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqLI_oGJt58w",
        "outputId": "375dac7e-ba2a-4ec9-9401-ac0fd47b94cf"
      },
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')  \n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1 / 10\n",
            "  Batch    50  of    117.\n",
            "  Batch   100  of    117.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.694\n",
            "Validation Loss: 0.690\n",
            "\n",
            " Epoch 2 / 10\n",
            "  Batch    50  of    117.\n",
            "  Batch   100  of    117.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.688\n",
            "Validation Loss: 0.678\n",
            "\n",
            " Epoch 3 / 10\n",
            "  Batch    50  of    117.\n",
            "  Batch   100  of    117.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.684\n",
            "Validation Loss: 0.679\n",
            "\n",
            " Epoch 4 / 10\n",
            "  Batch    50  of    117.\n",
            "  Batch   100  of    117.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.670\n",
            "Validation Loss: 0.658\n",
            "\n",
            " Epoch 5 / 10\n",
            "  Batch    50  of    117.\n",
            "  Batch   100  of    117.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.647\n",
            "Validation Loss: 0.630\n",
            "\n",
            " Epoch 6 / 10\n",
            "  Batch    50  of    117.\n",
            "  Batch   100  of    117.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.620\n",
            "Validation Loss: 0.605\n",
            "\n",
            " Epoch 7 / 10\n",
            "  Batch    50  of    117.\n",
            "  Batch   100  of    117.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.598\n",
            "Validation Loss: 0.608\n",
            "\n",
            " Epoch 8 / 10\n",
            "  Batch    50  of    117.\n",
            "  Batch   100  of    117.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.593\n",
            "Validation Loss: 0.571\n",
            "\n",
            " Epoch 9 / 10\n",
            "  Batch    50  of    117.\n",
            "  Batch   100  of    117.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.574\n",
            "Validation Loss: 0.570\n",
            "\n",
            " Epoch 10 / 10\n",
            "  Batch    50  of    117.\n",
            "  Batch   100  of    117.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.571\n",
            "Validation Loss: 0.555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIbxQqhIvRoF",
        "outputId": "f085c9e5-6985-41a2-a925-19504da4fdc8"
      },
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePraoirtvVBT"
      },
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()\n",
        "  preds = np.argmax(preds, axis = 1)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pmd2Zvc4FX3T",
        "outputId": "e398255e-0ef9-40aa-90a0-123144718878"
      },
      "source": [
        "print(preds)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbLFvm3tFBfX"
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "predresult =[]\n",
        "\n",
        "for item in preds:\n",
        "  if item == 1:\n",
        "    item = 'NOT_SARCASM'\n",
        "  else:\n",
        "    item = 'SARCASM'\n",
        "  predresult.append(item)\n",
        "\n",
        "with open ('testdata.csv') as f:\n",
        "  reader = csv.reader(f)\n",
        "  column = [row[2] for row in reader]\n",
        "\n",
        "#create test answer csv document\n",
        "with open ('testans.csv', 'w+', newline='', encoding='utf-8') as f:\n",
        "    csv_writer = csv.writer(f)\n",
        "\n",
        "    for i in range(len(predresult)):\n",
        "      data_row = [column[i+1],predresult[i]]\n",
        "      csv_writer.writerow(data_row)\n",
        "\n",
        "#conver csv to txt\n",
        "output = open ('answer.txt','w')\n",
        "with open('testans.csv', encoding='utf-8') as f:\n",
        "    for row in f:\n",
        "      output.write(row)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHMnpIVmaPx9"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    }
  ]
}